{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"PyMDPs","text":"<p>PyMDPs is a Python library for working with Markov Decision Processes (MDPs) and other related models like Partially Observable MDPs (POMDPs). It is designed to be easy to use and flexible, with a focus on providing a clean and intuitive API for defining and solving MDPs.</p>"},{"location":"index.html#features","title":"Features","text":"<ul> <li>Simple API: PyMDPs provides a simple and intuitive API for defining MDPs and solving them using a variety of algorithms.</li> <li>Modular Design: PyMDPs is designed to be modular and extensible, making it easy to add new algorithms and features.</li> <li>Well-Documented: PyMDPs comes with comprehensive documentation and examples to help you get started quickly.</li> <li>Open Source: PyMDPs is open source and released under the MIT license, so you are free to use it for any purpose.</li> </ul>"},{"location":"index.html#getting-started","title":"Getting Started","text":"<p>For an introduction to PyMDPs and a guide on how to get started, check out the Getting Started page.</p> <p>To quickly install PyMDPs, you can use pip:</p> <pre><code>pip install pymdps\n</code></pre>"},{"location":"index.html#documentation","title":"Documentation","text":"<p>The documentation is divided into the following sections:</p> <ul> <li>Getting Started: A guide to getting started with PyMDPs. This section covers installation instructions and a simple example of creating and solving an MDP.</li> <li>API Reference: The complete API reference for PyMDPs, including detailed descriptions of all classes and functions.</li> <li>Reference: This contains detailed information about the problems, algorithms, models, and other concepts used in PyMDPs.</li> </ul>"},{"location":"about/index.html","title":"About","text":"<p>About PyMDPs, it's design, inspiration, and more.</p>"},{"location":"about/alternatives.html","title":"Alternatives and Inspirations","text":"<p>PyMDPs wouldn't exist if not for the work of many other researchers and engineers in the field of reinforcement learning and decision making. Here are some of the libraries and tools that have inspired PyMDPs and that you might find useful for your own projects.</p> <ul> <li>POMDPs.jl POMDPs.jl is a Julia package for working with Partially Observable Markov Decision Processes (POMDPs). It provides a flexible and extensible framework for defining POMDPs and solving them using a variety of algorithms. This package was originally developed by Mykel Kochenderfer and collaborators at Stanford University.</li> <li>Gynmnasium Gynasium, formerly OpenAI Gym, is a toolkit for developing and comparing reinforcement learning algorithms. It supports teaching agents everything from walking to playing games like Pong or Pinball.</li> </ul>"},{"location":"about/contributing.html","title":"Contributing","text":""},{"location":"about/contributing.html#release-process","title":"Release Process","text":"<p>The release process for <code>pymdps</code> is as follows:</p> <ol> <li>Update the version number in <code>Cargo.toml</code> and <code>pyproject.toml</code>.</li> <li>Update the changelog in <code>CHANGELOG.md</code>.</li> <li>Commit the changes.</li> <li>Copy the contents of <code>CHANGELOG.md</code> to the release notes on GitHub.</li> <li>Create a new release on GitHub with the appropriate version number and release notes.<ol> <li>Create a new tag with the version number. DO NOT prefix the tag with <code>v</code>. (e.g. use <code>1.0.0</code> instead of <code>v1.0.0</code>)</li> <li>Name the release <code>vX.Y.Z</code> where <code>X.Y.Z</code> is the version number.</li> <li>Copy the contents of <code>CHANGELOG.md</code> to the release notes.</li> </ol> </li> </ol>"},{"location":"getting_started/index.html","title":"Getting Started","text":"<p>Welcome to PyMDPs! This section will help you get started with using the package. If it's your first time start with the First Steps page. Otherwise, you can jump to a specific topic using the links in the side bar.</p>"},{"location":"getting_started/first_steps.html","title":"First Steps","text":"<p>This page will guide you through the first steps of using the <code>pymdps</code> package. We will first make sure that the package is installed correctly, and then we will create a simple Markov Decision Process (MDP) and solve it using the Value Iteration algorithm.</p>"},{"location":"getting_started/first_steps.html#installation","title":"Installation","text":"<p>To install the package, you can use pip:</p> <pre><code>pip install pymdps\n</code></pre> <p>This will install the latest version of the package from PyPI. If you want to install the latest development version from GitHub, you can use:</p> <pre><code>pip install git+https://github.com/duncaneddy/pymdps\n</code></pre>"},{"location":"getting_started/first_steps.html#creating-an-mdp","title":"Creating an MDP","text":"<p>A Markov Decision Process (MDP) is defined by a tuple \\((S, A, P, R, \\gamma)\\) where \\(S\\) is the set of states, \\(A\\) is the set of actions, \\(P(s' \\mid s, a)\\) is the transition probability function, \\(R(s, a, s')\\) is the reward function, and \\(\\gamma\\) is the discount factor.</p> Python <pre><code>from pymdps import BaseMDP, MDPSolver\n\nclass MyMDP(BaseMDP):\n    def __init__(self):\n        super().__init__()\n\n    def states(self):\n        return ['s1', 's2', 's3']\n\n    def actions(self, state):\n        return ['a1', 'a2'] if state == 's1' else ['a3', 'a4']\n\n    def transition_probabilities(self, state, action):\n        return {'s1': 0.5, 's2': 0.5} if action == 'a1' else {'s3': 1.0}\n\n    def reward(self, state, action, next_state):\n        return 1.0\n\nif __name__ == '__main__':\n    mdp = MyMDP()\n\n    solver = MDPSolver(mdp)\n\n    solver.solve()\n\n    print('Done')\n</code></pre>"}]}